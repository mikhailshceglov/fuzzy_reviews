# Декомпозиция задачи

Ниже — разделение всей системы на три крупные части:

1. Офлайн-генерация авто-словаря (нейросетью).
2. NLP-обработка конкретного отзыва.
3. Нечёткая логика (fuzzy-ядро системы).

Каждый блок можно рассматривать как отдельный модуль/подсистему.

---

## 1. Офлайн-генерация авто-словаря (нейросетью)

**Цель:**
Построить *большой, доменно-независимый словарь* лемм с оценочной полярностью `polarity(w) ∈ [−1; 1]`, не выписывая его руками.

**Вход:**

* Большой корпус отзывов (разные домены).
* Предобученная модель сентимента по предложениям (NN).
* Морфологический анализатор для лемматизации.

**Что внутри делаем:**

1. **Лемматизируем корпус**

   * режем отзывы на предложения;
   * каждое предложение лемматизируем → список лемм.

2. **Прогоняем предложения через NN**

   * для каждого предложения получаем `sentiment_score ∈ [−1; 1]`.

3. **Собираем статистику по леммам**

   * для каждой леммы `w`:

     * собираем все `sentiment_score` предложений, где она встретилась;
     * считаем среднее → `polarity(w)`;
     * считаем частоту `freq(w)`.

4. **Фильтрация и чистка**

   * отбрасываем леммы с `freq(w) < N_min`;
   * по желанию — выкидываем явно служебные/стоп-слова;
   * делаем быструю ручную проверку:

     * топ-N самых позитивных / негативных / нейтральных;
     * немного подправляем руками (микро-редактирование).

**Выход:**

* Авто-лексикон: `словарь: лемма → polarity(w)`
  (плюс, при желании, частота `freq(w)` для контроля надёжности).

**Глобальная идея:**
Офлайн-часть строит **универсальный оценочный словарь**, используя нейросеть и статистику, чтобы потом онлайн-часть работала с *любым* отзывом без ручного перебора слов.

---

## 2. NLP-обработка конкретного отзыва

**Цель:**
Для *одного* отзыва превратить текст в набор **чётких числовых признаков** (`score_crisp`, интенсивность, неопределённость и т.п.), используя авто-словарь и простые правила.

**Вход:**

* Текст отзыва.
* Авто-словарь `лемма → polarity(w)`.
* Небольшой ручной список:

  * усилителей (`очень, безумно, супер…`),
  * хеджеров/смягчителей (`немного, слегка, скорее, в целом…`),
  * отрицание (`не`).

**Что внутри делаем:**

1. **Нормализация и лемматизация**

   * нижний регистр, очистка;
   * токенизация + лемматизация → последовательность лемм.

2. **Поиск в словаре**

   * для каждой леммы проверяем:

     * есть ли `polarity(w)` в авто-словаре;
     * является ли она усилителем / хеджером / «не».

3. **Учёт модификаторов на локальном уровне**

   * конструкции вида:

     * `усилитель + оценочное слово` → увеличиваем |polarity|;
     * `смягчитель + оценочное слово` → уменьшаем |polarity|;
     * `не + позитивное` / `не + негативное` → сдвигаем полярность к нулю или слегка меняем знак.

4. **Агрегация в численные фичи**

   * считаем:

     * `pos = Σ polarity(w) для polarity > 0`;
     * `neg = Σ −polarity(w) для polarity < 0`;
   * **главный скор**:
     [
     score_crisp = \frac{pos - neg}{pos + neg + 1}
     ]
   * дополнительные:

     * `emotion_intensity_crisp` = Σ |polarity(w)| или среднее;
     * `hedges_count` = количество хеджеров;
     * `coverage` = доля слов, у которых есть `polarity(w)` (покрытие словарём).

**Выход:**

* Набор чисел для отзыва:

  * `score_crisp`, `pos`, `neg`,
  * `emotion_intensity_crisp`,
  * `hedges_count`,
  * `coverage`.

**Глобальная идея:**
NLP-блок — это **мост “текст → числа”**: он берёт отзыв, авто-словарь и простые шаблоны и выдаёт компактный числовой портрет тональности и размытости высказывания.

---

## 3. Всё остальное: нечеткая логика (fuzzy-ядро системы)

**Цель:**
Взять численные признаки из NLP-блока и превратить их в **человечески понятную оценку**: «скорее положительно/отрицательно», с учётом эмоциональной силы, неопределённых формулировок и качества покрытия словарём.

**Вход:**

* `score_crisp`, `pos`, `neg`,
* `emotion_intensity_crisp`,
* `hedges_count`,
* `coverage`.

**Что внутри делаем:**

1. **Определяем лингвистические переменные**
   Примеры:

   * **Общая_тональность** (аргумент: `score_crisp`, диапазон [−1; 1])
     Термы: «сильно_отрицательная», «умеренно_отрицательная», «нейтральная», «умеренно_положительная», «сильно_положительная».

   * **Интенсивность_эмоций** (аргумент: `emotion_intensity_crisp`)
     Термы: «низкая», «средняя», «высокая».

   * **Лингвистическая_неопределённость** (аргумент: `hedges_count`)
     Термы: «почти_нет», «умеренная», «сильная».

   * **Надёжность_лексикона** (аргумент: `coverage`)
     Термы: «низкая», «средняя», «высокая».

   Выходные переменные:

   * **Итоговая_тональность** (со своими термами, как у `Общая_тональность`);
   * **Доверие_к_оценке** («низкое, среднее, высокое»).

2. **Фаззификация**

   * задаём для каждого терма функции принадлежности (треугольники/трапеции);
   * получаем μ-значения:

     * μ_умеренно_положительная(score_crisp),
     * μ_интенсивность_высокая(emotion_intensity_crisp),
     * μ_неопределённость_сильная(hedges_count),
     * μ_надёжность_низкая(coverage),
     * и т.д.

3. **Нечеткий вывод (база правил)**
   Примеры правил:

   * ЕСЛИ `Общая_тональность` = «умеренно_положительная»
     И `Интенсивность_эмоций` = «низкая»
     И `Лингвистическая_неопределённость` = «почти_нет»
     И `Надёжность_лексикона` = «высокая»
     ТО `Итоговая_тональность` = «слабоположительная»
     И `Доверие_к_оценке` = «высокое».

   * ЕСЛИ `Общая_тональность` = «нейтральная»
     И `Лингвистическая_неопределённость` = «сильная»
     ТО `Итоговая_тональность` = «нейтральная»
     И `Доверие_к_оценке` = «низкое».

   * ЕСЛИ `pos` ≈ `neg`
     И `Интенсивность_эмоций` = «высокая»
     ТО `Итоговая_тональность` = «контрастная».

   Алгоритм Мамдани/Сугено агрегирует все правила → даёт нечеткие множества для выходных переменных.

4. **Дефаззификация**

   * `Итоговая_тональность` → `final_score ∈ [−1; 1]` или [0; 100];
   * `Доверие_к_оценке` → `reliability ∈ [0; 1]`.

   Плюс лингвистический вывод для человека:

   * «скорее положительный отзыв, умеренные эмоции, формулировки почти без неопределённости, надёжность высокая»;
   * «нейтральный отзыв, много размытых формулировок, доверие низкое».

**Выход:**

* Число: итоговый индекс тональности.
* Число: доверие к оценке.
* Лингвистическое описание (термы), которые объясняют результат.

**Глобальная идея:**
Fuzzy-ядро — это **мозг системы**: оно берёт “сырые” числа из NLP, превращает их в размытые лингвистические оценки и через правила выдаёт человекопонятный, «мягкий» вердикт с учётом неопределённости и надёжности.

